{
  "id": "c88b5cd2-67b7-44cd-bb9d-8fe4294b9933",
  "filename": "2062118f-8a44-48f6-a99a-8c11029f9d82.pdf",
  "page_count": 1,
  "pages": [
    {
      "page": 1,
      "text": "# Lojistik Regresyon (Logistic Regression)\n\n## Temel Sınıflandırma Mantığı\n\n*   **Geleneksel Sınıflandırma:** Bir nesneyi birden çok sınıftan birine ($A, B, C$) atamaktır.\n*   **Doğal Dil İşleme (NLP) Modellemesi:** Girdi (önceki kelimeler) verildiğinde, çıktı (sonraki kelime), kelime dağarcığındaki her bir olası kelimeden birine atanır.\n*   **Modelin Çalışması:** Model, her kelime için bir olasılık hesaplar ve en yüksek olasılığa sahip kelimeyi (sınıfı) seçer.\n*   Bu süreç, genellikle çok sınıflı (multi-class) bir sınıflandırma problemidir.\n\n## Metinlerin Olasılık Kullanılarak Sınıflandırılması\n\n1.  **Ön İşleme:** Metin, sayısal bir listeye ($x$) dönüştürülür.\n2.  **Olasılık Hesaplama:** Sayısal girdi ($x$) kullanılarak, metnin her bir olası sınıfa ($y$) ait olma olasılığı hesaplanır.\n3.  **Tahmin:** Olasılık değeri, matematiksel formüller kullanılarak hesaplanır ve nihai tahmin çıkarılır.\n\n## Model Eğitimi ve Kayıp Fonksiyonu\n\n*   **Karşılaştırma:** Gerçek değer ve tahmin karşılaştırılır. Hata (Loss) değerinin 0'a yakın olması hedeflenir.\n*   **Kayıp Fonksiyonu:** Hata miktarını ölçmek için **Çapraz Entropi Kaybı** (Cross-Entropy Loss) kullanılır.\n*   **Optimizasyon:** Hata puanını azaltmak için modeldeki ağırlıkları ($w$) yavaş ve akıllıca düzeltmek gerekir. Bu işlem **Stokastik Gradyan İnişi** (Stochastic Gradient Descent, SGD) ile yapılır.\n\n---\n\n## Lojistik Regresyonun İki Aşaması\n\n### 1. Eğitim Aşaması\n\nModel, binlerce etiketlenmiş metin örneği üzerinde çalışır.\n\n*   **Optimizasyon Kullanımı:** **Stokastik Gradyan İnişi** ve **Çapraz Entropi Kaybı** ölçütleri kullanılarak, modelin öğrenilebilir parametreleri (ağırlıklar ($w$) ve yanlılık terimi ($b$)) öğrenilir.\n\n### 2. Test veya Çıkarım Aşaması\n\nDaha önce görmediği bir metin örneği ($x$) modele verilir.\n\n*   **Olasılık Hesaplama:** Model, öğrenilmiş ağırlıkları ($w$) ve yanlılık terimini ($b$) kullanarak, bu metnin her bir sınıfına ait olma koşullu olasılığını $P(y|x)$ hesaplar.\n\n$$ P(y|x) = \\frac{1}{1 + e^{-(w \\cdot x + b)}} $$\n\n*   **Nihai Tahmin:** Model, olasılığı daha yüksek olan etiketi nihai tahmin olarak verir:\n    *   $y = 1$ \\[Pozitif Sınıf]\n    *   $y = 0$ \\[Negatif Sınıf]",
      "raw_text": "ri #eayiendurmnoda , bir nesneyi Ğ sadğlor bire m\n\ndl .C) ölkrama Da Modelleme , Girdi (önceki kelimeler)\nAfmde » bileği (seneler kerme) kelime depar cişandet. m\n\nher Si alen kelimaden bine or. Model, her kerme\n\nika b olsslik hesmer ve an yek alasılşo «Hip p\n\nketmeyr CS ay Geden), Bu gok Sey arr Slordime\n\nPrblemdir. p\n\nBüçisoyr meter olosik kulede suyloadırır ger.\n\nMehti Sywol Gr lisleye dörşher\nSaysd Liseyi , metnin her Wr elesi Sule ot oWs olosiim pr.\nhesap1. Tohma üker\n\nOlosuk depet hesaplar , melemohksel Arwiiler kullanlan. - pr\n\nGercek ve İohmin Larşloşirir\n\nNel ©'o yotn Ma Epi koye Eyes VS, E-\n\nHelo pvorm asli mode (deki dörikleri Yovoş ve okulca Bi”\ndezesr.\n\nLöyetk Ne çidsyen İki Agemecı\n\n1 Eğiren Açomesı Medeli, binlerce erkeler\nEgGEMdE UuoUşır\n\nSlokosiik Grdum iii vw Gop? Entropi koğbi oyları\n\nkulorleok. , ARrulelorı Cw) ve yete terimia' Ce) öpeenir\n\nç Mean &nep\n\n2. Test Ep Gikom Pçovosı Yoko E50Ce görmediği bo\n© meka Srneçi€x) modele vir\n\nyek (> ve la kuleeoe, bu mein her bir Se of ölme\n\nç Oloslğm P/gİx) haseper”\n\nole , elesiği dehe yemek. olen ee ye | Eeonnf 3"
    }
  ]
}